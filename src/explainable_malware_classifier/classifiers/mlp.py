import os
from typing import Any

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from timeit import default_timer as timer

import pandas as pd
from scipy.sparse import csc_matrix
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.metrics import classification_report, f1_score
from sklearn.preprocessing import LabelEncoder
import joblib

from explainable_malware_classifier.classifiers.utils import comma_tokenizer

# Cross-Validation f1_macro scores: [0.7686812610711948, 0.7462761016899245, 0.773855501005583, 0.7690167276895005,
# 0.7546487101953104, 0.7651481079283229, 0.7509331504432555, 0.7673117488037757, 0.7591574075253188, 0.7301319991505382]
# Cross-Validation f1_macro mean:   0.7585
# Cross-Validation f1_macro std:    0.0133
# --------------------------------------------------
# Classification Report:
#                precision    recall  f1-score   support
#
#       adware       0.82      0.67      0.74       282
#     backdoor       0.80      0.75      0.77       352
#   downloader       0.68      0.77      0.72       231
#      dropper       0.60      0.50      0.55       173
#      spyware       0.48      0.59      0.53       172
#       trojan       0.93      0.96      0.94      2883
#        virus       0.97      0.94      0.95      1076
#        worms       0.72      0.65      0.68       399
#
#     accuracy                           0.87      5568
#    macro avg       0.75      0.73      0.74      5568
# weighted avg       0.87      0.87      0.87      5568
#
# --------------------------------------------------
# Model artifacts have been saved to: mlp_model.joblib
# Total Runtime(s): 2145.22


class MalwareClassifierMLP:
    class MalwareNet(nn.Module):
        def __init__(self, input_dim: int, hidden_dim: int, num_classes: int):
            super().__init__()
            self.net = nn.Sequential(
                nn.Linear(input_dim, hidden_dim),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(hidden_dim, hidden_dim),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(hidden_dim, num_classes),
            )

        def forward(self, x):
            return self.net(x)

    def __init__(
        self,
        max_features: int = 20_000,
        ngram_range: tuple[int, int] = (1, 2),
        epochs: int = 50,
        batch_size: int = 64,
        hidden_dim: int = 256,
        learning_rate: float = 0.001,
        device: str = None,
        num_workers: int = -1,
        random_state: int = 69,
    ):
        self.random_state = random_state
        self.device = (
            device if device else ("cuda" if torch.cuda.is_available() else "cpu")
        )
        self.num_workers = num_workers if num_workers != -1 else os.cpu_count()
        self.epochs = epochs
        self.batch_size = batch_size
        self.learning_rate = learning_rate
        self.hidden_dim = hidden_dim
        self.vectorizer = TfidfVectorizer(
            tokenizer=comma_tokenizer,
            token_pattern=None,
            max_features=max_features,
            ngram_range=ngram_range,
        )
        self.label_encoder = LabelEncoder()
        # set after fit_transform
        self.model = None
        self.input_dim = None
        self.num_classes = None

    def load_and_transform_data(self, csv_path: str) -> tuple[np.ndarray, np.ndarray]:
        df = pd.read_csv(csv_path)
        X_csr = self.vectorizer.fit_transform(df["api"])
        X = csc_matrix(X_csr).toarray()  # convert to dense for PyTorch
        y_encoded = self.label_encoder.fit_transform(df["class"])
        self.input_dim = X.shape[1]
        self.num_classes = len(self.label_encoder.classes_)
        self.model = self.MalwareNet(self.input_dim, self.hidden_dim, self.num_classes)
        self.model.to(self.device)
        return X, y_encoded

    def _train_one_epoch(
        self, model: MalwareNet, dataloader: DataLoader, criterion: Any, optimizer: Any
    ):
        """
        One epoch of training over the given dataloader.
        """
        model.train()
        total_loss = 0.0
        for batch_x, batch_y in dataloader:
            batch_x, batch_y = batch_x.to(self.device), batch_y.to(self.device)
            optimizer.zero_grad()
            outputs = model(batch_x.float())
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            total_loss += loss.item() * batch_x.size(0)
        return total_loss

    def _evaluate(self, model: MalwareNet, dataloader: DataLoader) -> tuple[list, list]:
        """
        Evaluate the model and return true and predicted class labels.
        """
        model.eval()
        true_list, pred_list = [], []
        with torch.no_grad():
            for batch_x, batch_y in dataloader:
                batch_x = batch_x.to(self.device)
                outputs = model(batch_x.float())
                pred = torch.argmax(outputs, dim=1).cpu().numpy()
                pred_list.extend(pred)
                true_list.extend(batch_y.numpy())
        return true_list, pred_list

    def _prepare_train_test_data(
        self,
        model: MalwareNet,
        X_train: np.ndarray,
        y_train: np.ndarray,
        X_test: np.ndarray,
        y_test: np.ndarray,
    ):
        # convert train and val folds to DataLoaders for batching, shuffle and performance
        train_ds = TensorDataset(
            torch.tensor(X_train, dtype=torch.float32),
            torch.tensor(y_train, dtype=torch.long),
        )
        test_ds = TensorDataset(
            torch.tensor(X_test, dtype=torch.float32),
            torch.tensor(y_test, dtype=torch.long),
        )
        train_loader = DataLoader(
            train_ds,
            batch_size=self.batch_size,
            shuffle=True,
            num_workers=self.num_workers,
            pin_memory=True,
        )
        test_loader = DataLoader(
            test_ds,
            batch_size=self.batch_size,
            shuffle=False,
            num_workers=self.num_workers,
            pin_memory=True,
        )
        # define loss and optimizer
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=self.learning_rate)
        return train_loader, test_loader, criterion, optimizer

    def cross_validate(
        self,
        X: np.ndarray,
        y: np.ndarray,
        cv_splits: int = 10,
        scoring: str = "f1_macro",
    ):
        """
        Performs cross-validation in a manner similar to scikit-learn.
        """
        kfold = StratifiedKFold(
            n_splits=cv_splits, shuffle=True, random_state=self.random_state
        )
        scores = []

        for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X, y), 1):
            # re-init model for each fold
            fold_model = self.MalwareNet(
                self.input_dim, self.hidden_dim, self.num_classes
            ).to(self.device)

            train_loader, val_loader, criterion, optimizer = (
                self._prepare_train_test_data(
                    fold_model, X[train_idx], y[train_idx], X[val_idx], y[val_idx]
                )
            )

            for epoch in range(self.epochs):
                _ = self._train_one_epoch(
                    fold_model, train_loader, criterion, optimizer
                )
            val_true, val_pred = self._evaluate(fold_model, val_loader)
            fold_score = f1_score(val_true, val_pred, average=scoring.split("_")[1])
            scores.append(float(fold_score))
            print(f"Fold {fold_idx}, {scoring}={fold_score:.4f}")

        print(f"Cross-Validation {scoring} scores:", scores)
        print(f"Cross-Validation {scoring} mean:   {np.mean(scores):.4f}")
        print(f"Cross-Validation {scoring} std:    {np.std(scores, ddof=1):.4f}")
        print("-" * 50)

    def train_and_evaluate(self, X: np.ndarray, y: np.ndarray, test_size: float = 0.2):
        """
        Train on the training split, then evaluate on the test split.
        """
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=self.random_state
        )

        train_loader, test_loader, criterion, optimizer = self._prepare_train_test_data(
            self.model, X_train, y_train, X_test, y_test
        )

        for epoch in range(self.epochs):
            _ = self._train_one_epoch(self.model, train_loader, criterion, optimizer)

        y_true_encoded, y_pred_encoded = self._evaluate(self.model, test_loader)
        y_true = self.label_encoder.inverse_transform(y_true_encoded)
        y_pred = self.label_encoder.inverse_transform(y_pred_encoded)
        print("Classification Report:\n", classification_report(y_true, y_pred))
        print("-" * 50)

    def save_model(self, filename: str):
        """
        Save the PyTorch model state_dict, along with vectorizer and label_encoder
        in a joblib file for convenience.
        """
        model_artifacts = {
            "model_state_dict": self.model.state_dict(),
            "input_dim": next(self.model.parameters()).shape[1],
            "hidden_dim": self.hidden_dim,
            "label_encoder": self.label_encoder,
            "vectorizer": self.vectorizer,
        }
        joblib.dump(model_artifacts, filename)
        print(f"Model artifacts have been saved to: {filename}")

    @staticmethod
    def load_model(filename: str):
        """
        Load the model artifacts, restore the model, vectorizer, and label encoder.
        Returns a tuple: (restored_model, vectorizer, label_encoder)
        """
        model_artifacts = joblib.load(filename)
        input_dim = model_artifacts["input_dim"]
        hidden_dim = model_artifacts["hidden_dim"]
        label_encoder = model_artifacts["label_encoder"]
        vectorizer = model_artifacts["vectorizer"]

        # reconstruct the model architecture
        num_classes = len(label_encoder.classes_)
        restored_model = MalwareClassifierMLP.MalwareNet(
            input_dim, hidden_dim, num_classes
        )
        restored_model.load_state_dict(model_artifacts["model_state_dict"])
        restored_model.eval()

        return restored_model, vectorizer, label_encoder

    def run(self) -> None:
        start_time = timer()
        X, y = self.load_and_transform_data("../datasets/preprocessed_merged_seq.csv")
        # self.cross_validate(X, y, cv_splits=10, scoring="f1_macro")
        self.train_and_evaluate(X, y)
        # self.save_model("mlp_model.joblib")
        print("Total Runtime(s):", round(timer() - start_time, 2))
