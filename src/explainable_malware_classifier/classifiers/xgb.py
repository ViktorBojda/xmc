from timeit import default_timer as timer
from typing import Any

import pandas as pd
from scipy.sparse import csc_matrix
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.preprocessing import LabelEncoder
import joblib
from sklearn.utils import compute_sample_weight
from xgboost import XGBClassifier

from explainable_malware_classifier.classifiers.base import BaseMalwareClassifier
from explainable_malware_classifier.classifiers.utils import comma_tokenizer

# Cross-Validation f1_macro scores: [0.77105666 0.75528998 0.78475892 0.7620221  0.76012389 0.78275331
#  0.76787781 0.77188261 0.75019322 0.74313781]
# Cross-Validation f1_macro mean:  0.7649096316035252
# Cross-Validation f1_macro std:   0.012735670995888137
# --------------------------------------------------
# Classification Report:
#                precision    recall  f1-score   support
#
#       adware       0.62      0.87      0.73       282
#     backdoor       0.61      0.83      0.70       352
#   downloader       0.77      0.81      0.79       231
#      dropper       0.60      0.74      0.66       173
#      spyware       0.57      0.62      0.59       172
#       trojan       0.97      0.86      0.91      2883
#        virus       0.95      0.95      0.95      1076
#        worms       0.68      0.71      0.70       399
#
#     accuracy                           0.85      5568
#    macro avg       0.72      0.80      0.75      5568
# weighted avg       0.87      0.85      0.86      5568
#
# --------------------------------------------------
# Model artifacts have been saved to: xgb_model.pkl
# Total Runtime: 3281.32


class MalwareClassifierXGB(BaseMalwareClassifier):
    def __init__(
        self,
        eval_metric="mlogloss",
        n_estimators=450,
        max_depth=8,
        learning_rate=0.1,
        subsample=0.9,
        colsample_bytree=0.75,
        min_child_weight=3,
        gamma=0.005,
        tree_method="hist",
        random_state=69,
        verbosity=2,
        device="cuda",
        n_jobs=None,
    ):
        self.random_state = random_state
        self.vectorizer = TfidfVectorizer(
            tokenizer=comma_tokenizer,
            token_pattern=None,
            max_features=20_000,
            ngram_range=(1, 2),
        )
        self.label_encoder = LabelEncoder()
        self.classifier = XGBClassifier(
            eval_metric=eval_metric,
            n_estimators=n_estimators,
            max_depth=max_depth,
            learning_rate=learning_rate,
            subsample=subsample,
            colsample_bytree=colsample_bytree,
            min_child_weight=min_child_weight,
            gamma=gamma,
            tree_method=tree_method,
            random_state=self.random_state,
            verbosity=verbosity,
            n_jobs=n_jobs,
            device=device,
        )

    def load_and_transform_data(self, csv_path: str) -> tuple[Any, Any]:
        df = pd.read_csv(csv_path)
        X = csc_matrix(self.vectorizer.fit_transform(df["api"]))
        y_encoded = self.label_encoder.fit_transform(df["class"])
        return X, y_encoded

    def cross_validate(
        self, X: Any, y: Any, cv_splits: int = 10, scoring: str = "f1_macro"
    ) -> None:
        kfold = StratifiedKFold(
            n_splits=cv_splits, shuffle=True, random_state=self.random_state
        )
        sample_weight = compute_sample_weight("balanced", y)
        cv_scores = cross_val_score(
            self.classifier,
            X,
            y,
            cv=kfold,
            scoring=scoring,
            verbose=3,
            n_jobs=1,
            params={"sample_weight": sample_weight},
        )
        print(f"Cross-Validation {scoring} scores:", cv_scores)
        print(f"Cross-Validation {scoring} mean:  {cv_scores.mean()}")
        print(f"Cross-Validation {scoring} std:   {cv_scores.std()}")
        print("-" * 50)

    def train_and_evaluate(self, X: Any, y: Any, test_size: float = 0.2) -> None:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=self.random_state
        )
        sample_weight = compute_sample_weight("balanced", y_train)
        self.classifier.fit(
            X_train,
            y_train,
            sample_weight=sample_weight,
        )
        y_pred_encoded = self.classifier.predict(X_test)
        y_pred_decoded = self.label_encoder.inverse_transform(y_pred_encoded)
        y_test_decoded = self.label_encoder.inverse_transform(y_test)
        self.plot_confusion_matrix(
            y_test_decoded,
            y_pred_decoded,
            title="XGB Confusion Matrix",
            save_as="xgb_conf_matrix.png",
        )
        print(
            "Classification Report:\n",
            classification_report(y_test_decoded, y_pred_decoded),
        )
        print("-" * 50)

    def save_model(self, filename: str) -> None:
        joblib.dump((self.classifier, self.vectorizer, self.label_encoder), filename)
        print(f"Model artifacts have been saved to: {filename}")

    @staticmethod
    def load_model(filename: str) -> tuple[Any, Any, Any]:
        classifier, vectorizer, label_encoder = joblib.load(filename)
        return classifier, vectorizer, label_encoder

    def run(self) -> None:
        start_time = timer()
        X, y = self.load_and_transform_data("../datasets/preprocessed_merged_seq.csv")
        self.cross_validate(X, y, cv_splits=10)
        self.train_and_evaluate(X, y)
        self.save_model("xgb_model.pkl")
        print("Total Runtime(s):", round(timer() - start_time, 2))
