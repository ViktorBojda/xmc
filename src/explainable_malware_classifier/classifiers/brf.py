from typing import Any

import numpy as np
import shap
from imblearn.ensemble import BalancedRandomForestClassifier
from matplotlib import pyplot as plt
from scipy.sparse import csc_matrix
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.preprocessing import LabelEncoder

from explainable_malware_classifier.classifiers.base import BaseMalwareClassifier
from explainable_malware_classifier.classifiers.utils import save_plot
from explainable_malware_classifier.utils import timer


# Cross-Validation f1_macro scores: [0.7592, 0.7473, 0.7722, 0.7537, 0.7409, 0.7659, 0.7389, 0.7658, 0.7591, 0.7188]
# Cross-Validation f1_macro mean:   0.7522
# Cross-Validation f1_macro std:    0.0160
# --------------------------------------------------
# Classification Report:
#                precision    recall  f1-score   support
#
#       adware       0.88      0.62      0.73       282
#     backdoor       0.87      0.75      0.81       352
#   downloader       0.82      0.77      0.80       231
#      dropper       0.53      0.73      0.62       173
#      spyware       0.50      0.64      0.56       172
#       trojan       0.89      0.98      0.93      2883
#        virus       0.98      0.88      0.93      1076
#        worms       0.86      0.53      0.66       399
#
#     accuracy                           0.87      5568
#    macro avg       0.79      0.74      0.75      5568
# weighted avg       0.88      0.87      0.87      5568
#
# --------------------------------------------------
# Finished MalwareClassifierBRF.run() in 5590.28 secs


class MalwareClassifierBRF(BaseMalwareClassifier):
    model_name = "brf.joblib"

    def __init__(
        self,
        n_estimators=200,
        max_depth=31,
        replacement=True,
        bootstrap=False,
        sampling_strategy="not majority",
        min_samples_split: int = 2,
        min_samples_leaf: int = 1,
        rf_max_features=None,
        random_state=69,
        verbose=3,
        n_jobs=-1,
    ):
        """
        Initialize the classifier with desired hyperparameters.
        Also sets up a TfidfVectorizer and LabelEncoder.
        """
        self.random_state = random_state
        self.vectorizer = TfidfVectorizer(
            tokenizer=self.comma_tokenizer,
            token_pattern=None,
            max_features=10_000,
            ngram_range=(1, 2),
            sublinear_tf=False,
        )
        self.label_encoder = LabelEncoder()
        self.classifier = BalancedRandomForestClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            replacement=replacement,
            bootstrap=bootstrap,
            sampling_strategy=sampling_strategy,
            min_samples_split=min_samples_split,
            min_samples_leaf=min_samples_leaf,
            max_features=rf_max_features,
            random_state=self.random_state,
            verbose=verbose,
            n_jobs=n_jobs,
        )

    def cross_validate(
        self,
        X: csc_matrix,
        y: np.ndarray,
        *,
        cv_splits: int = 10,
        scoring: str = "f1_macro",
    ) -> None:
        """
        Performs Stratified K-Fold cross-validation and prints the scores.
        """
        kfold = StratifiedKFold(
            n_splits=cv_splits, shuffle=True, random_state=self.random_state
        )
        cv_scores = cross_val_score(
            self.classifier, X, y, cv=kfold, scoring=scoring, verbose=1, n_jobs=-1
        )
        self.display_cv_results(scoring, cv_scores)

    def train_and_evaluate(
        self, X: np.ndarray, y: np.ndarray, *, test_size: float = 0.2
    ) -> None:
        """
        Splits data into train/test, fits the classifier on training set,
        predicts on the test set, decodes the labels, and prints a classification report.
        """
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=self.random_state
        )
        self.classifier.fit(X_train, y_train)
        y_pred_encoded = self.classifier.predict(X_test)
        y_pred = self.label_encoder.inverse_transform(y_pred_encoded)
        y_true = self.label_encoder.inverse_transform(y_test)
        print("Classification Report:\n", classification_report(y_true, y_pred))
        self.plot_confusion_matrix(
            y_true, y_pred, title="BRF Confusion Matrix", save_as="brf_conf_matrix"
        )
        print("-" * 50)
        self.save_model_artifacts(X_train, X_test, y_train, y_test)

    def get_model_artifacts(self) -> dict[str, Any]:
        artifacts = super().get_model_artifacts()
        artifacts["model"] = self.classifier
        return artifacts

    def explain(self):
        artifacts = self.load_model_artifacts()
        model = artifacts["model"]
        feature_names = artifacts["feature_names"]
        X_test, y_test = artifacts["X_test"], artifacts["y_test"]
        explainer = shap.GPUTreeExplainer(model, feature_names=feature_names)
        explanation = explainer(X_test)
        y_pred = model.predict(X_test)
        max_display = 30
        plt.figure(clear=True)
        for class_idx, class_name in enumerate(artifacts["label_encoder"].classes_):
            class_explanation = explanation[:, :, class_idx]
            plt.clf()
            shap.plots.beeswarm(
                class_explanation,
                max_display=max_display,
                group_remaining_features=False,
                show=False,
            )
            save_plot(
                f"SHAP Beeswarm Plot for Class: {class_name} (Mean Avg)",
                f"brf/shap/beeswarm/mean_avg/{class_name}",
            )
            max_positive_shap = np.max(
                np.where(class_explanation.values > 0, class_explanation.values, 0),
                axis=0,
            )
            order = np.argsort(-max_positive_shap)
            plt.clf()
            shap.plots.beeswarm(
                class_explanation,
                max_display=max_display,
                order=order,
                group_remaining_features=False,
                show=False,
            )
            save_plot(
                f"SHAP Beeswarm Plot for Class: {class_name} (High Positive)",
                f"brf/shap/beeswarm/high_positive/{class_name}",
            )
            true_indices = np.where((y_test == class_idx) & (y_pred == class_idx))[0]
            false_indices = np.where((y_test == class_idx) & (y_pred != class_idx))[0]
            if true_indices.size > 0:
                idx = true_indices[0]
                instance_explanation = class_explanation[idx]
                instance_features = X_test[idx]
                plt.clf()
                shap.plots.decision(
                    instance_explanation.base_values,
                    instance_explanation.values,
                    instance_features,
                    feature_names,
                    show=False,
                )
                save_plot(
                    f"SHAP Decision Plot for Class: {class_name} (Correct)",
                    f"brf/shap/decision/correct/{class_name}",
                )
            if false_indices.size > 0:
                idx = false_indices[0]
                instance_explanation = class_explanation[idx]
                instance_features = X_test[idx]
                plt.clf()
                shap.plots.decision(
                    instance_explanation.base_values,
                    instance_explanation.values,
                    instance_features,
                    feature_names,
                    show=False,
                )
                save_plot(
                    f"SHAP Decision Plot for Class: {class_name} (Misclassified)",
                    f"brf/shap/decision/misclassified/{class_name}",
                )
        plt.close("all")

    @timer
    def run(self) -> None:
        X, y = self.load_and_transform_data()
        self.cross_validate(X, y, cv_splits=10, scoring="f1_macro")
        self.train_and_evaluate(X.toarray(), y)
        self.explain()
