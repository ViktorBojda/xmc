from timeit import default_timer as timer
from typing import Any

import pandas as pd
from imblearn.ensemble import BalancedRandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.preprocessing import LabelEncoder
import joblib


def comma_tokenizer(text: str) -> list[str]:
    return text.split(",")


# Cross-Validation F1 Macro scores: [0.74793602 0.77000448 0.74830535 0.75303668 0.73675809 0.7750543
#  0.74919314 0.7513593  0.74513045 0.74750489]
# Cross-Validation F1 Macro mean:   0.7524282697774279
# Cross-Validation F1 Macro std:    0.01092277694971424
# --------------------------------------------------
# Classification Report:
#                precision    recall  f1-score   support
#
#       adware       0.89      0.65      0.75       301
#     backdoor       0.92      0.71      0.80       354
#   downloader       0.75      0.77      0.76       244
#      dropper       0.52      0.72      0.60       168
#      spyware       0.42      0.55      0.47       152
#       trojan       0.89      0.98      0.93      2941
#        virus       1.00      0.88      0.93      1134
#        worms       0.85      0.57      0.68       343
#
#     accuracy                           0.87      5637
#    macro avg       0.78      0.73      0.74      5637
# weighted avg       0.88      0.87      0.87      5637
# --------------------------------------------------
# Total Runtime: 409.94


class MalwareClassifierBRF:
    def __init__(
        self,
        n_estimators=500,
        replacement=True,
        bootstrap=False,
        sampling_strategy="not majority",
        random_state=69,
        verbose=1,
        n_jobs=-1,
    ):
        """
        Initialize the classifier with desired hyperparameters.
        Also sets up a TfidfVectorizer and LabelEncoder.
        """
        self.random_state = random_state
        self.vectorizer = TfidfVectorizer(
            tokenizer=comma_tokenizer,
            token_pattern=None,
            min_df=5,
            max_df=0.9,
            ngram_range=(1, 1),
        )
        self.label_encoder = LabelEncoder()
        self.classifier = BalancedRandomForestClassifier(
            n_estimators=n_estimators,
            replacement=replacement,
            bootstrap=bootstrap,
            sampling_strategy=sampling_strategy,
            random_state=self.random_state,
            verbose=verbose,
            n_jobs=n_jobs,
        )

    def load_and_transform_data(
        self, csv_path: str
    ) -> tuple[pd.DataFrame, pd.DataFrame]:
        """
        Loads data from a CSV file, transforms it via TF-IDF,
        encodes labels, and returns (X, y) arrays.
        """
        df = pd.read_csv(csv_path)
        X = self.vectorizer.fit_transform(df["api"])
        y_encoded = self.label_encoder.fit_transform(df["class"])
        return X, y_encoded

    def cross_validate(
        self,
        X: pd.DataFrame,
        y: pd.DataFrame,
        cv_splits: int = 10,
        scoring: str = "f1_macro",
    ) -> None:
        """
        Performs Stratified K-Fold cross-validation and prints the scores.
        """
        kfold = StratifiedKFold(
            n_splits=cv_splits, shuffle=True, random_state=self.random_state
        )
        cv_scores = cross_val_score(
            self.classifier, X, y, cv=kfold, scoring=scoring, verbose=1, n_jobs=-1
        )
        print(f"Cross-Validation {scoring} scores:", cv_scores)
        print(f"Cross-Validation {scoring} mean:  {cv_scores.mean()}")
        print(f"Cross-Validation {scoring} std:   {cv_scores.std()}")
        print("-" * 50)

    def train_and_evaluate(
        self, X: pd.DataFrame, y: pd.DataFrame, test_size: float = 0.2
    ) -> None:
        """
        Splits data into train/test, fits the classifier on training set,
        predicts on the test set, decodes the labels, and prints a classification report.
        """
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=self.random_state
        )
        self.classifier.fit(X_train, y_train)
        y_pred_encoded = self.classifier.predict(X_test)
        y_pred = self.label_encoder.inverse_transform(y_pred_encoded)
        y_test_decoded = self.label_encoder.inverse_transform(y_test)
        print("Classification Report:\n", classification_report(y_test_decoded, y_pred))
        print("-" * 50)

    def save_model(self, filename: str) -> None:
        """
        Saves the classifier, TF-IDF vectorizer, and label encoder to a file.
        """
        joblib.dump((self.classifier, self.vectorizer, self.label_encoder), filename)
        print(f"Model artifacts have been saved to: {filename}")

    @staticmethod
    def load_model(filename: str) -> tuple[Any, Any, Any]:
        """
        Loads the classifier, TF-IDF vectorizer, and label encoder from a file.
        Returns them as a tuple (classifier, vectorizer, label_encoder).
        """
        classifier, vectorizer, label_encoder = joblib.load(filename)
        return classifier, vectorizer, label_encoder

    def run(self) -> None:
        start_time = timer()
        X, y = self.load_and_transform_data("../datasets/preprocessed_merged.csv")
        self.cross_validate(X, y, cv_splits=10, scoring="f1_macro")
        self.train_and_evaluate(X, y)
        self.save_model("brf_model.pkl")
        print("Total Runtime:\n", round(timer() - start_time, 2))
