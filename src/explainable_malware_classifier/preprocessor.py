import os

import numpy as np
import pandas as pd

removed_mangled_api_calls = 0


def aggregate_api_calls(row: pd.Series, data: dict):
    api_calls = []
    count = 0
    for col_name, value in row.items():
        count += 1
        if col_name == "sha256":
            continue
        api_calls.extend([col_name] * value)
    if not api_calls:
        return
    sha = row["sha256"]
    if sha in data:
        raise ValueError("Duplicate sha256 in dataset")
    data[sha] = {"api": api_calls}


def assign_malware_class(row: pd.Series, data: dict):
    sha = row["sha256"]
    if sha in data:
        data[sha]["class"] = row["class"]


def preprocess_drzehra_dataset():
    df = pd.read_csv("datasets/drzehra_api_calls.csv")
    df.drop(columns=["malware"], inplace=True)  # all are malware
    data = {}
    df.apply(lambda row: aggregate_api_calls(row, data), axis=1)

    df = pd.read_csv("datasets/drzehra_malware_class.csv")
    df.apply(lambda row: assign_malware_class(row, data), axis=1)

    csv_data = [
        {"file": sha, "api": ",".join(values["api"]), "class": values["class"]}
        for sha, values in data.items()
        if "class" in values
    ]
    pd.DataFrame(csv_data).to_csv("datasets/drzehra_preprocessed.csv", index=False)
    print("Successfully preprocessed drzehra dataset")


def remove_mangled_api_calls(api_string: str):
    global removed_mangled_api_calls
    api_list = api_string.split(",")
    filtered_list = [api for api in api_list if not api.startswith("?")]
    removed_mangled_api_calls += len(api_list) - len(filtered_list)
    clean_api_calls = ",".join(filtered_list)
    if clean_api_calls:
        return clean_api_calls
    return np.nan


def is_within_limits(row, limits: dict[str, tuple[int, int]]):
    cls = row["class"]
    lower, upper = limits[cls]
    if row["api_count"] < lower or row["api_count"] > upper:
        return np.nan
    return row


def preprocess_datasets():
    df1 = pd.read_csv("datasets/VirusSample.csv")
    df2 = pd.read_csv("datasets/VirusShare.csv")
    if not os.path.exists("datasets/drzehra_preprocessed.csv"):
        preprocess_drzehra_dataset()
    df3 = pd.read_csv("datasets/drzehra_preprocessed.csv")
    df = pd.concat([df1, df2, df3], ignore_index=True)
    print("Rows before preprocess: " + str(len(df)))

    df["api"] = df["api"].apply(remove_mangled_api_calls)
    df.dropna(inplace=True)
    print("Number of mangled API calls removed: " + str(removed_mangled_api_calls))
    print("Rows after removing missing values: " + str(len(df)))

    df["class"] = df["class"].str.lower()
    df = df[(df["class"] != "undefined") & (df["class"] != "unknown")]
    print("Rows after removing class 'undefined' and 'unknown': " + str(len(df)))

    df["api_count"] = df["api"].apply(lambda x: len(x.split(",")))
    print(f'Minimum number of API calls: {df["api_count"].min()}')
    print(f'Maximum number of API calls: {df["api_count"].max()}')

    MIN_API_COUNT = 3
    df = df[df["api_count"] >= MIN_API_COUNT]
    print(
        f"Rows after removing those where API count is less than {MIN_API_COUNT}: {str(len(df))}"
    )

    limits = {}
    for cls in df["class"].unique():
        subset = df[df["class"] == cls]
        lower_limit = int(subset["api_count"].quantile(0.1))
        upper_limit = int(subset["api_count"].quantile(0.9))
        limits[cls] = (lower_limit, upper_limit)
        print(
            f"Class: {cls}\t\t Lower Limit: {lower_limit}\t\t Upper Limit: {upper_limit}"
        )
    df = df.apply(lambda row: is_within_limits(row, limits), axis=1)
    df.dropna(inplace=True)
    print(f"Rows after removing class specific outliers: {str(len(df))}")

    class_counts = df["class"].value_counts()
    print("Class distribution:")
    print(class_counts)

    MIN_CLASS_SAMPLE = 80
    classes_to_drop = class_counts[class_counts < 80].index.tolist()
    df = df[~df["class"].isin(classes_to_drop)]
    print(
        f"Rows after removing classes with less than {MIN_CLASS_SAMPLE} samples: {str(len(df))}"
    )

    print(f'Minimum number of API calls: {df["api_count"].min()}')
    print(f'Maximum number of API calls: {df["api_count"].max()}')

    df.to_csv("datasets/preprocessed_combined.csv", index=False)
    print(
        "Successfully preprocessed datasets. Saved to datasets/preprocessed_combined.csv"
    )


if __name__ == "__main__":
    preprocess_datasets()
